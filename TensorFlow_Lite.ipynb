{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in c:\\users\\vikra\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\vikra\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NZKNhx8x_1jq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ymcbpqPdLJxW"
   },
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_vfRLdF_LKUK"
   },
   "outputs": [],
   "source": [
    "def convert_bytes(size, unit=None):\n",
    "    if unit == \"KB\":\n",
    "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
    "    elif unit == \"MB\":\n",
    "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
    "    else:\n",
    "        return print('File size: ' + str(size) + ' bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Import the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "This guide uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 32s 7us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TRFYHB2mCaWb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XKnCTHz4CaWg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqTxmbVBASQF"
   },
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2KFnYlcwCaWl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iJmPr5-ACaWn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "m4VEw8Ud9Quh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[88])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Build & Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss= SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xvwvpA64CaW_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 972us/step - loss: 0.4944 - accuracy: 0.8268\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3741 - accuracy: 0.8647\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1000us/step - loss: 0.3358 - accuracy: 0.8781s - loss: 0.3\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.3104 - accuracy: 0.88630s - loss:\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2958 - accuracy: 0.8895\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2811 - accuracy: 0.8957\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2660 - accuracy: 0.9009\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2571 - accuracy: 0.9050\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2467 - accuracy: 0.9079\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 958us/step - loss: 0.2382 - accuracy: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f36682f8c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4n4_BRNKLRwo"
   },
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME = \"tf_model_fashion_mnist.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "A_3Y3F4GBWud"
   },
   "outputs": [],
   "source": [
    "model.save(KERAS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "19sd1FJkCHID"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 1.19 Megabytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Y_deKtkhCHMu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3239 - accuracy: 0.8856\n",
      "\n",
      "Test accuracy: 0.8855999708175659\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BFE9lvwLfgv"
   },
   "source": [
    "# TF Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ORAx4Yc7LjwM"
   },
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NY57t7EwCW8P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vikra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\vikra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\vikra\\AppData\\Local\\Temp\\tmpng8fqx4d\\assets\n"
     ]
    }
   ],
   "source": [
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "# tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = tf_lite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CZxnt1IsCXBb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103776"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
    "open(tflite_model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "XtIdP296CXFl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 101.344 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_gttI3-M45M"
   },
   "source": [
    "# Check Input Tensor Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "IJXJuGLFGfjB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [ 1 28 28]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [ 1 10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_X-k46vMzAt"
   },
   "source": [
    "# Resize Tensor Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "M6wo8RNFGpXw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [10000    28    28]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [10000    10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 28, 28))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zsv7ROq8Gf0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SM1alowAHy2d"
   },
   "outputs": [],
   "source": [
    "test_imgs_numpy = np.array(test_images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wm4bxTIwHErB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yRKoF30HIZP2"
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(prediction_classes, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FZIF6OenI_5i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy TFLITE model : 0.8846\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy TFLITE model :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw7r5WyUV307"
   },
   "source": [
    "# Get Weights of Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Lzqy6REGPxIA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3239264 <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(model.get_weights()[0][0][0], type(model.get_weights()[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "drZEEbY5RXJk"
   },
   "outputs": [],
   "source": [
    "keras_weight_var = np.array([model.get_weights()[0][0][0]], dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "oIwkH2EYWKom"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsizeof(keras_weight_var[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuSUIDA_WZ9V"
   },
   "source": [
    "# Access Quantized Weights of TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fbzyyvetWhCs"
   },
   "outputs": [],
   "source": [
    "TF_LITE_WEIGHTS_TEMP_FILE = \"temp_weights_from_tflite.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "hV83qjttPz5E"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL_FILE_NAME)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "all_layers_details = interpreter.get_tensor_details() \n",
    "f = h5py.File(TF_LITE_WEIGHTS_TEMP_FILE, \"w\")   \n",
    "for layer in all_layers_details:\n",
    "     grp = f.create_group(str(layer['index']))\n",
    "     grp.attrs[\"name\"] = layer['name']\n",
    "     grp.attrs[\"shape\"] = layer['shape']\n",
    "     grp.attrs[\"quantization\"] = layer['quantization']\n",
    "     grp.create_dataset(\"weights\", data=interpreter.get_tensor(layer['index']))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "oTi8OzHmUZF1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "temp_file = h5py.File(TF_LITE_WEIGHTS_TEMP_FILE, 'r')\n",
    "print(temp_file[\"5\"][\"weights\"][0][6], type(temp_file[\"5\"][\"weights\"][0][6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "dcdUtejoW73F"
   },
   "outputs": [],
   "source": [
    "quantized_weight_var = np.array([temp_file[\"5\"][\"weights\"][0][6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Udfbq6fTXCxa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsizeof(quantized_weight_var[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zUF9xC2iZVsb"
   },
   "outputs": [],
   "source": [
    "temp_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vv4y9DS5ZX71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlow_Lite.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
